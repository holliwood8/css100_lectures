{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "565fd595",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Introduction to `pytorch`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58997db4-551c-4a50-973a-e8fc2a4d2df2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Lecture plan\n",
    "\n",
    "- Introduction to [`pytorch`](https://pytorch.org/tutorials/beginner/basics/intro.html).\n",
    "   - Working with **tensors**.\n",
    "- Building a simple network.\n",
    "   - A simple classification problem using `torch`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32656f90-3e2d-43a8-bfb9-eb8f07bea8f3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Introduction to `pytorch`\n",
    "\n",
    "- There are a *bunch* of Python packages for using neural networks.\n",
    "    - `torch`, `keras`, `tensorflow`, and more!\n",
    "- Plus other packages, like `transformers`, to use specific kinds of networks (e.g., **large language models**).\n",
    "- In our introduction, we'll use `pytorch`.\n",
    "- To follow along in DataHub, you'll need to use the *Machine Learning* container."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f6c51cf-aaa2-47ea-bac8-94914001e784",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### About `pytorch`\n",
    "\n",
    "> `pytorch` is a Python library originally developed by Facebook's AI Research (FAIR) lab).\n",
    "\n",
    "- It provides a flexible *interface* for constructing and training neural networks.\n",
    "- To understand `torch`, we'll start out by introducing `tensors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d55747-26f7-4e7a-90ba-f5be2379cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d304060e-7b6f-4c8f-b263-711317acaf49",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Introduction to `tensors`\n",
    "\n",
    "> A **tensor** is a specialized data structure, similar to arrays or matrices.\n",
    "\n",
    "- In `torch`, `tensors` are used to encode the *parameters* of a model, as well as the inputs and outputs.\n",
    "- Very similar to `np.array`, except they can run on GPUs——more efficient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e53c6e-6c78-48cf-86de-0217c87c2627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02eab589-1b49-4707-9134-e17e5f4663dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Compare to numpy\n",
    "import numpy as np\n",
    "x_data_np = np.array(data)\n",
    "x_data_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51913d7d-ab36-48e8-b7df-f17d5a34d0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Converting from numpy\n",
    "torch.from_numpy(x_data_np)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aab75c3c-6399-423f-a8db-81a1be4580a8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Basic attributes\n",
    "\n",
    "- Like a `np.array`, `tensors` have some key attributes like `shape`.\n",
    "- Tensors can also be located on `cpu` or another `device`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eccc8079-bc45-45ec-a3f8-c78f594946e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create random tensor\n",
    "random_tensor = torch.rand(3,4)\n",
    "### Shape\n",
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b83a4396-2857-4754-9962-c0bbb7ab46ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Type of tensor\n",
    "random_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2354d8c-74f5-4bb1-9ef9-7337d7222680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Device\n",
    "random_tensor.device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c0df675-55d9-4ba8-b94e-daf4ab70e452",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Working with `tensors`\n",
    "\n",
    "- Like a `np.array`, we can *index* into `tensors` using the `tensor_name[index]` operation.\n",
    "- We can also **concatenate** and **stack** these tensors.\n",
    "    - **Concatenating**: combine along a given dimension.\n",
    "    - **Stacking**: combine along a new dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a457d6e5-d9ad-40e7-919f-4e249c92fd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8411, 0.5068, 0.1831, 0.1839])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Indexing\n",
    "random_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef0e0f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8411)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34c57d84-9bb5-4992-9801-ac1b56252993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8411, 0.5068, 0.1831, 0.1839],\n",
      "        [0.0546, 0.0110, 0.7278, 0.9758],\n",
      "        [0.8322, 0.0206, 0.5546, 0.0594],\n",
      "        [0.8411, 0.5068, 0.1831, 0.1839],\n",
      "        [0.0546, 0.0110, 0.7278, 0.9758],\n",
      "        [0.8322, 0.0206, 0.5546, 0.0594]])\n"
     ]
    }
   ],
   "source": [
    "### Concatenating\n",
    "t1 = torch.cat([random_tensor, random_tensor], dim=0) # cat puts them on top of each other\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61e99d81-798a-42eb-b033-e1f83888caa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7764, 0.4538, 0.2200, 0.3751],\n",
      "         [0.9257, 0.2293, 0.2515, 0.0129],\n",
      "         [0.9153, 0.7054, 0.7420, 0.6229]],\n",
      "\n",
      "        [[0.7764, 0.4538, 0.2200, 0.3751],\n",
      "         [0.9257, 0.2293, 0.2515, 0.0129],\n",
      "         [0.9153, 0.7054, 0.7420, 0.6229]]])\n"
     ]
    }
   ],
   "source": [
    "### Concatenating\n",
    "t1 = torch.stack([random_tensor, random_tensor], dim=0) # stack nests the tensors in a bigger tensor\n",
    "print(t1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "737cf3a6-84ea-4f8b-897a-79e1fd195ebb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Math with `tensors`\n",
    "\n",
    "- Like a `np.array`, we can apply *arithmetic operations* to our `tensor` objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ba7e125-64e2-406d-955f-f595c5f9ba63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c69d2691-1e2f-4ae6-9c51-d455eb3f0f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4],\n",
       "        [ 9, 16]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Element wise product\n",
    "a * a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6db519b4-6799-4653-b088-ed030434d0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 4],\n",
       "        [6, 8]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Element wise sum\n",
    "a + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "789951bb-157f-4ca3-82c8-535776a72ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Sum each column\n",
    "a.sum(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a422c815-728a-49b3-bf80-cbc1beca487d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 7])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Sum each row\n",
    "a.sum(dim = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8352940-4a93-4d6b-9d67-848aa92c27de",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Using `torch` `Datasets`\n",
    "\n",
    "- `pytorch` also has a custom `Dataset` class that can be used to represent the data to train neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b21a8c16-5247-4dad-a0a0-ba32a13b1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "580918bd-edd1-46b1-9cc8-298b862fbe5b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### The `FashionMNIST` Dataset\n",
    "\n",
    "- The `FashionMNIST` dataset contains images of *parts of clothing* (e.g., a shirt, socks, etc.) along with their labels.\n",
    "- Intended as a replacement for classic [MNIST](https://en.wikipedia.org/wiki/MNIST_database), a handwritten digit classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5077b269-a757-4d4c-b63c-01f5f73b662c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a03652f5-4dda-4c56-a491-cbdddf767270",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Working with the `FashionMNIST` dataset\n",
    "\n",
    "- There are 60K trianing observations.\n",
    "- Each observation is a `(28, 28)` `tensor` array of *pixels*, along with a *label*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ea2a0ab-4359-44dd-92d7-c056699415df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Size of data\n",
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "345cbdd5-554c-4d5a-beae-51cc9ae33f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Map label onto actual clothing type\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\", 1: \"Trouser\",\n",
    "    2: \"Pullover\", 3: \"Dress\",\n",
    "    4: \"Coat\", 5: \"Sandal\",\n",
    "    6: \"Shirt\", 7: \"Sneaker\",\n",
    "    8: \"Bag\", 9: \"Ankle Boot\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a87f453b-725b-41d5-a189-18db17085796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "T-Shirt\n"
     ]
    }
   ],
   "source": [
    "img, label = training_data[2]\n",
    "print(img.shape)\n",
    "print(labels_map[label])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70d0f472-1026-4218-8991-92ed3a767ae5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Working with the `FashionMNIST` dataset\n",
    "\n",
    "We can also *visualize* examples from some of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7582f6c-1621-4c8c-80ae-69dac5b40862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 1\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5047e23e-d741-4aa0-833d-41b29bd116f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Batching and the `DataLoader`\n",
    "\n",
    "> A **batch** is a small, manageable chunk of your dataset.\n",
    "\n",
    "- Training neural networks is typically done in **non-overlapping batches**.\n",
    "    - Tends to improve efficiency.\n",
    "    - Allows the model to learn from different *samples* of data, which improves generalization.\n",
    "- The `DataLoader` object helps us deal with processing and sampling the data in these batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a87f6c4-55cf-4f8c-b532-b2ce50d2e218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a069ba1-1f03-4ac4-b396-b7cd474652ae",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### A `DataLoader` wrapper\n",
    "\n",
    "- Here, we set `batch_size = 64`.\n",
    "- That means that for any given **forward** and **backward** pass through network, we are processing `64` training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98042a5c-00bf-47fd-aab1-2e0223b5adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8c903a7-dfdc-4752-82ab-66b0517ef7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X: [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape}\")\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b067baf6-f3c6-4f6d-a156-e3f24df8c739",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Interim summary\n",
    "\n",
    "- `pytorch` contains various classes and operations to handle your *data*.\n",
    "- `tensors` are analogous to `numpy` arrays.\n",
    "   - All data and model parameters are represented as `tensors`.\n",
    "- `pytorch` also contains classes to help with **training**.\n",
    "   - `Dataset`.\n",
    "   - `DataLoader`\n",
    " \n",
    "> But how do we actually build the **neural networks**?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39f49803-70c9-4e97-ad7a-2e8e815b920a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Building our first *neural network*\n",
    "\n",
    "In this section, we'll build a simple **neural network** object in `pytorch`, and train it on a classification task."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "680f929b-1e80-436a-bd32-7f6fe11dd406",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Creating the class\n",
    "\n",
    "- The `NeuralNetwork` class is a subclass of the `nn.Module` class.\n",
    "- Any network built in `torch` should be a *subclass* of `nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76a4a6ee-42b9-4f83-95ea-d481bb8de950",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # inherit from nn.Module (parent class)\n",
    "        self.flatten = nn.Flatten() # flatten to 1D\n",
    "        self.linear_relu_stack = nn.Sequential( # define NN layers\n",
    "            nn.Linear(28*28, 512), # input size 28*28, output size 512 (512 hidden units)\n",
    "            nn.ReLU(), # activation function\n",
    "            nn.Linear(512, 512), # input size 512, output size 512 (512 hidden units)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10), # input size 512, output size 10 (10 classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x) # logits are the raw predictions. to get probabilities, apply activation function\n",
    "        return logits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed30134e-6d90-49df-8986-14a64bc1b2a6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Understanding our class (1)\n",
    "\n",
    "```python\n",
    "    def __init__(self):\n",
    "        \n",
    "        ### Inherits nn.Module properties\n",
    "        super().__init__()\n",
    "        \n",
    "        ### Flattens input tensor\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        ### Creates actual neural network structure!\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512), ### First layer\n",
    "            nn.ReLU(), ### ctivation function\n",
    "            nn.Linear(512, 512), ### another hidden layer\n",
    "            nn.ReLU(), ### anotehr activation function\n",
    "            nn.Linear(512, 10), ### final layer = output \n",
    "        )\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3bb89860-acae-4f97-aa4a-2bc4cfc5a494",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Check-in\n",
    "\n",
    "Try to explain the dimensionality of the following model properties:\n",
    "\n",
    "- `nn.Linear(28*28, 512)`\n",
    "- `nn.Linear(512, 512)`\n",
    "- `nn.Linear(512, 10)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a16a2250-21a3-4071-b9a7-0aff938be182",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your answer here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "baa52628-86a5-4fb8-802d-f91c54ef9add",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Understanding model dimensionality\n",
    "\n",
    "- `nn.Linear(28*28, 512)`: input is `28x28` pixel arrays; maps to `512` hidden units\n",
    "- `nn.Linear(512, 512)`: hidden layer has `512` inputsn and `512` outputs.\n",
    "- `nn.Linear(512, 10)`: another layer with `512` inputs but `10` outputs, for the `10` output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4b2e88b-697a-4ed4-92b4-75714de9660a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data.classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c50d599-dc24-43fa-ba3c-db94330fccc0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Understanding our class (2)\n",
    "\n",
    "> The `forward` function defines how to run the model \"forward\" on some input.\n",
    "\n",
    "- First, `flatten` the input array.\n",
    "- Then, run the input through our `linear_relu_stack` we defined in `__init__`.\n",
    "\n",
    "```python\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fb955ea-01ab-4cf7-aa43-d3c1170905ec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Instantiating the class\n",
    "\n",
    "- We can create an *instance* of the `NeuralNetwork` class, and `print` its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94415872-1934-44c7-b179-f39b1192a61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d1b6971-4798-4e45-95a4-70def0910bad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Running the model\n",
    "\n",
    "- We can run the model **forward** by feeding it random pixels.\n",
    "- This yields `logits`, i.e., real values assigned to different output classes.\n",
    "- We can apply the **softmax** function to turn `logits` into a probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70255fa4-afd2-41ec-a126-b57a753237c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0679,  0.0372, -0.0211,  0.0051,  0.0551,  0.0123,  0.0780,  0.0268,\n",
       "         -0.0218, -0.0350]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Random input array\n",
    "X = torch.rand(1, 28, 28)\n",
    "### Run model forward\n",
    "logits = model(X)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d42dfeb9-9428-453d-a53a-5ec846661319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([6])\n"
     ]
    }
   ],
   "source": [
    "### Softmax\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "### What did we predict?\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75c0bea0-78c3-435d-a364-2e1600e88611",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### What are our *parameters*?\n",
    "\n",
    "> The **parameters**, or **weights**, determine how representations are changed across layers.\n",
    "\n",
    "- Initially, these are **randomly sampled** from a uniform distribution.\n",
    "- These are what we want to *change*, ultimately!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d971e430-0e34-4da0-8d46-aedce7e58a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_relu_stack.0.weight\n",
      "torch.Size([512, 784])\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "### First parameter name\n",
    "print(params[0][0])\n",
    "### Parameter size\n",
    "print(params[0][1].size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec30ccd4-bc48-4f69-9bdb-e0655b8cb5f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Understanding `nn.Linear`\n",
    "\n",
    "- To get a better understanding of how this works, we can create an arbitrary `nn.Linear` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "805c266f-31aa-43a9-95cf-41782fa05b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "### New layer\n",
    "linear_layer = nn.Linear(10, 10)\n",
    "print(linear_layer.weight.shape)\n",
    "print(linear_layer.bias.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a7945b8-3fb1-4616-ba47-c3e6c5ddb490",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Let's train the model!\n",
    "\n",
    "- Above, we just built the **architecture** of our model.\n",
    "- To *train it*, we need to:\n",
    "    - Define our **hyper-parameters**.\n",
    "    - Define a **loss function**.\n",
    "    - Decide on an **optimizer**.\n",
    "    - Give our neural network some **training data**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0a91e78-2aed-42a6-b91b-efad883db3bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Setting up our hyperparameters\n",
    "\n",
    "> A **hyper-parameter** is an adjustable parameter controlling the training process; your choice of hyperparameter can have a big impact on model performance.\n",
    "\n",
    "- **Number of Epochs**: the number times to iterate over the dataset. \n",
    "- **Batch Size**: the number of data samples propagated through the network before the parameters are updated. \n",
    "- **Learning Rate**: how much to update models parameters at each batch/epoch.\n",
    "    - Smaller values result in slower learning speed.\n",
    "    - Larger values can result in unpredictable behavior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f82bfe60-d300-4eaf-9e4e-23a3c3899dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d439eb9d-a4b2-48ec-b106-48d9222c05c1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### The optimization \"loop\"\n",
    "\n",
    "> An **epoch** is a single cycle of this optimization loop.\n",
    "\n",
    "- Once we've decided our hyper-parameters, we *train* and *optimize* with an **optimization loop**.\n",
    "- During *training*, we update our parameters to reduce error.\n",
    "- During *validation/testing*, we iterate over our test data to see if performance is improving.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2da6c3df-b9cb-4272-b1e2-0d2356d9c931",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### A loss function\n",
    "\n",
    "> A **loss function** defines how to *penalize* the model when it gets its predictions wrong.\n",
    "\n",
    "- We will use the **cross-entropy loss**, which is common for neural networks.\n",
    "\n",
    "$$ L(p,y)= -\\sum_{i=1}^Cy_ilog(p_i)$$\n",
    "\n",
    "- Technically, since $y$ is just a **one-hot encoding**, this simplifies considerably to:\n",
    "\n",
    "$$L(p,y)=−log(p_k)$$\n",
    "\n",
    "- Where $k$ is the label for the true class.\n",
    "- This simplified version is the same as **surprisal**, the \"information value\" of an event.\n",
    "    - We want a model that *minimizes surprisal* of the *true class*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8badfb66-3339-4814-b516-689c9b6b81a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining loss in pytorch\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d24ca5cf-92de-4aa0-a1cd-0cf14b89fea9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### An optimizer\n",
    "\n",
    "> An **optimizer** determines the algorithm for updating weights.\n",
    "\n",
    "- There are [many different optimizers](https://pytorch.org/docs/stable/optim.html) available in `torch`.\n",
    "- A common approach is **stochastic gradient descent (SGD)**.\n",
    "- In SGD, you use a **random subset** of your data to update your model parameters each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90167005-15ca-4ed3-b3e9-d95742756c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting up optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "221d1316-88e4-4b7d-a8e3-4f63ed1d862b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Our `train_loop`\n",
    "\n",
    "Here, we define a function (straight from `torch`) to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "587dc16f-a77c-41ae-b273-ee20102447e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93c6d38e-fa43-4ef9-924f-e883848e2698",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Our `test_loop`\n",
    "\n",
    "Here, we define a function (straight from `torch`) to test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c4accef-08c1-4543-9a5b-c8adad37c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99bf690f-8e44-4a41-922a-441f3e6831aa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Let's train it!\n",
    "\n",
    "Here, we train for only two `epochs`. Training on more `epochs` would improve performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87e4dccb-a6f5-4526-b8e3-e3c88499168b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.291107  [   64/60000]\n",
      "loss: 2.282079  [ 6464/60000]\n",
      "loss: 2.260382  [12864/60000]\n",
      "loss: 2.254068  [19264/60000]\n",
      "loss: 2.226992  [25664/60000]\n",
      "loss: 2.206361  [32064/60000]\n",
      "loss: 2.211154  [38464/60000]\n",
      "loss: 2.174390  [44864/60000]\n",
      "loss: 2.162379  [51264/60000]\n",
      "loss: 2.132716  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.123447 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.132315  [   64/60000]\n",
      "loss: 2.121489  [ 6464/60000]\n",
      "loss: 2.056823  [12864/60000]\n",
      "loss: 2.070019  [19264/60000]\n",
      "loss: 1.995198  [25664/60000]\n",
      "loss: 1.949159  [32064/60000]\n",
      "loss: 1.966345  [38464/60000]\n",
      "loss: 1.881123  [44864/60000]\n",
      "loss: 1.877946  [51264/60000]\n",
      "loss: 1.798860  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 1.802260 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af8b0897-0f19-41d4-ab22-0ddce0c3f728",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Inspecting our *fit* model\n",
    "\n",
    "- Now, we have a model with **fit parameters**.\n",
    "- We can *inspect* these parameters using the `model.state_dict()` function.\n",
    "- You can also [`save` these parameters to disk](https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html), should you choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0dbb012a-0646-4888-9442-9155276b523a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['linear_relu_stack.0.weight', 'linear_relu_stack.0.bias', 'linear_relu_stack.2.weight', 'linear_relu_stack.2.bias', 'linear_relu_stack.4.weight', 'linear_relu_stack.4.bias'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = model.state_dict()\n",
    "### Parameters\n",
    "params.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8abea2d1-7d09-49c0-be61-0a9e95d23ab8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Lecture wrap-up\n",
    "\n",
    "- `pytorch` is a widely-used library for **building** and **training** neural networks.\n",
    "- It relies on the `tensor` object, which is like a `np.array`.\n",
    "- Building a neural network involves some other processes, including:\n",
    "    - Setting up your data in a `DataLoader`.\n",
    "    - Defining your model **architecture** in a new class (that inherits from `nn.Module`).\n",
    "    - Setting up your **hyper-parameters**, **loss function**, and **optimizer**.\n",
    "    - Training the model!\n",
    "- Once trained, a model can be applied to new data."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
